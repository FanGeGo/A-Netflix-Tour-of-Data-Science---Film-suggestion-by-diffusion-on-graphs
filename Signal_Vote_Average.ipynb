{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Netflix Tour of Data Science - Film suggestion by diffusion on graphs\n",
    "# Signal - Vote average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Students:\n",
    "\n",
    "    * Team     : 17\n",
    "    * Students : Edwige Avignon, Kenneth Nguyen, Pierre Fourcade  \n",
    "    * Dataset  : Kaggle dataset - Films and Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook:\n",
    "\n",
    "This notebook is used to extract and export the signal that we are going to use for the project: the average vote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note here that when we computed the different adjacency matrices, we haven't removed the isolated nodes that, usually and in our case, do not carry meaningful informations.\n",
    "However, keeping them doesn't do any harm and it makes the extraction of the signal more convenient: we simply take the full signal from the dataset, no need to order or remove any node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygsp as pg\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv('Dataset_Exports/tmdb_5000_credits.csv')\n",
    "movies = pd.read_csv('Dataset_Exports/tmdb_5000_movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Signal - Vote average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the signal from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_vote_average = np.array(movies.vote_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export two forms of the signal: one in csv so that we can apply it in Gephi and an other to work with PyGSP.\n",
    "We also export the signal placed into bins. As the average vote can go from 0 to 10 we create 11 bins: 0, 1, 2,... and 10.\n",
    "\n",
    "The signal placed into those bins is more convenient for representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.zeros(len(movie_vote_average))\n",
    "\n",
    "for i in range (len(signal)):\n",
    "    signal[i] = movie_vote_average[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Dataset_Exports/Vote_average_base_signal.txt', signal)\n",
    "\n",
    "df_signal = pd.DataFrame(signal)\n",
    "df_signal.to_csv('Dataset_Exports/Vote_average_base_signal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We place the signal into the bins described:\n",
    "\n",
    "signal_bin = np.zeros(len(signal))\n",
    "\n",
    "for i in range (len(signal_bin)):\n",
    "    if movie_vote_average[i] < 0.5:\n",
    "        signal_bin[i] = 0\n",
    "    elif movie_vote_average[i] >= 0.5 and movie_vote_average[i] < 1.5:\n",
    "        signal_bin[i] = 1\n",
    "    elif movie_vote_average[i] >= 1.5 and movie_vote_average[i] < 2.5:\n",
    "        signal_bin[i] = 2\n",
    "    elif movie_vote_average[i] >= 2.5 and movie_vote_average[i] < 3.5:\n",
    "        signal_bin[i] = 3\n",
    "    elif movie_vote_average[i] >= 3.5 and movie_vote_average[i] < 4.5:\n",
    "        signal_bin[i] = 4\n",
    "    elif movie_vote_average[i] >= 4.5 and movie_vote_average[i] < 5.5:\n",
    "        signal_bin[i] = 5\n",
    "    elif movie_vote_average[i] >= 5.5 and movie_vote_average[i] < 6.5:\n",
    "        signal_bin[i] = 6\n",
    "    elif movie_vote_average[i] >= 6.5 and movie_vote_average[i] < 7.5:\n",
    "        signal_bin[i] = 7\n",
    "    elif movie_vote_average[i] >= 7.5 and movie_vote_average[i] < 8.5:\n",
    "        signal_bin[i] = 8\n",
    "    elif movie_vote_average[i] >= 8.5 and movie_vote_average[i] < 9.5:\n",
    "        signal_bin[i] = 9\n",
    "    else:\n",
    "        signal_bin[i] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Dataset_Exports/Vote_average_base_signal_bin.txt', signal_bin)\n",
    "\n",
    "df_signal_bin = pd.DataFrame(signal_bin)\n",
    "df_signal_bin.to_csv('Dataset_Exports/Vote_average_base_signal_bin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add this signal to the different dataframe made with Gephi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_Cast_Nodes = pd.read_csv('Dataset_Exports/Cast/Graph_Cast_Nodes.csv')\n",
    "Graph_Cast_Nodes['vote_average0'] = signal_bin\n",
    "Graph_Cast_Nodes.to_csv('Dataset_Exports/Cast/Graph_Cast_Nodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_First_Role_Nodes = pd.read_csv('Dataset_Exports/First_Role/Graph_First_Role_Nodes.csv')\n",
    "Graph_First_Role_Nodes['vote_average0'] = signal_bin\n",
    "Graph_First_Role_Nodes.to_csv('Dataset_Exports/First_Role/Graph_First_Role_Nodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_Genres_Nodes = pd.read_csv('Dataset_Exports/Genres/Graph_Genres_Nodes.csv')\n",
    "Graph_Genres_Nodes['vote_average0'] = signal_bin\n",
    "Graph_Genres_Nodes.to_csv('Dataset_Exports/Genres/Graph_Genres_Nodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_Crew_Nodes = pd.read_csv('Dataset_Exports/Crew/Graph_Crew_Nodes.csv')\n",
    "Graph_Crew_Nodes['vote_average0'] = signal_bin\n",
    "Graph_Crew_Nodes.to_csv('Dataset_Exports/Crew/Graph_Crew_Nodes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
